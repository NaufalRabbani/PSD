
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Projek UAS &#8212; Projek Sains Data</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'project_psd';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Analisis Data Time Series" href="time-series_autocorr-based.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="profil.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/WhatsApp Image 2025-06-21 at 11.47.14_68dc4168.jpg" class="logo__image only-light" alt="Projek Sains Data - Home"/>
    <script>document.write(`<img src="_static/WhatsApp Image 2025-06-21 at 11.47.14_68dc4168.jpg" class="logo__image only-dark" alt="Projek Sains Data - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="profil.html">
                    Biodata
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bab-1_bu.html">Memahami Bisnis</a></li>
<li class="toctree-l1"><a class="reference internal" href="bab-2_du.html">Data Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="bab-3_dp.html"><strong>Data Preparation</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="time_series.html">Analisis Data Time Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="time-series_autocorr-based.html">Analisis Data Time Series</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Projek UAS</a></li>










</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fproject_psd.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/project_psd.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Projek UAS</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Projek UAS</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#business-understanding">Business Understanding</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#latar-belakang">Latar Belakang</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tujuan-bisnis">Tujuan Bisnis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definisi-masalah">Definisi Masalah</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-understanding">Data Understanding</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-dataset">Deskripsi Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-library">Load Library</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-data-konversi-label">LOAD DATA &amp; KONVERSI LABEL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cek-struktur-data">CEK STRUKTUR DATA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribusi-kelas">DISTRIBUSI KELAS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#missing-value-check">MISSING VALUE CHECK</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistik-deskriptif">STATISTIK DESKRIPTIF</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribusi-nilai-fitur-global">DISTRIBUSI NILAI FITUR (GLOBAL)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi-1-sampel">VISUALISASI 1 SAMPEL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-rata-rata-per-kelas">PERBANDINGAN RATA-RATA PER KELAS</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#heatmap-korelasi">HEATMAP KORELASI</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#outlier-detection-z-score">OUTLIER DETECTION (Z-SCORE)</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#variansi-fitur">VARIANSI FITUR</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#temuan-awal-dari-eda">Temuan Awal dari EDA</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation">Data Preparation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing">PREPROCESSING</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#penggabungan-dataset">Penggabungan Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tahapan-preprocessing">Tahapan Preprocessing</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#validasi-penanganan-missing-value">VALIDASI &amp; PENANGANAN MISSING VALUE</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-outlier-dengan-clipping">HANDLING OUTLIER DENGAN CLIPPING</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-scaling">FEATURE SCALING</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-reduksi-dimensi">PCA – REDUKSI DIMENSI</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-output-untuk-modeling">FINAL OUTPUT UNTUK MODELING</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling">Modeling</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">Evaluation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-semua-model">Perbandingan semua model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insight-evaluasi">Insight Evaluasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menyimpan-model">Menyimpan model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menyimpan-data-untuk-test-setelah-deployment">Menyimpan data untuk test setelah deployment</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#deployment">Deployment</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-aplikasi">Implementasi Aplikasi</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#app-py">app.py</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#requirements-txt">requirements.txt</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explainability-shap">Explainability (SHAP)</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-future-work">Conclusion &amp; Future Work</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">Kesimpulan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pengembangan-lanjutan">Pengembangan Lanjutan</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="projek-uas">
<h1>Projek UAS<a class="headerlink" href="#projek-uas" title="Link to this heading">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="business-understanding">
<h1>Business Understanding<a class="headerlink" href="#business-understanding" title="Link to this heading">#</a></h1>
<section id="latar-belakang">
<h2>Latar Belakang<a class="headerlink" href="#latar-belakang" title="Link to this heading">#</a></h2>
<p>Pemeriksaan keamanan menggunakan citra X-ray bagasi merupakan proses penting untuk mendeteksi keberadaan perangkat listrik tersembunyi (electric devices) di dalam tas atau koper. Proses inspeksi manual oleh petugas keamanan memiliki keterbatasan, antara lain:</p>
<ul class="simple">
<li><p>Ketergantungan pada pengalaman operator</p></li>
<li><p>Potensi kelelahan manusia</p></li>
<li><p>Waktu pemeriksaan yang terbatas</p></li>
</ul>
<p>Oleh karena itu, diperlukan sistem otomatis berbasis machine learning yang mampu membantu proses deteksi perangkat listrik secara cepat dan konsisten.</p>
</section>
<section id="tujuan-bisnis">
<h2>Tujuan Bisnis<a class="headerlink" href="#tujuan-bisnis" title="Link to this heading">#</a></h2>
<p>Tujuan dari proyek ini adalah:</p>
<ul class="simple">
<li><p>Membangun model klasifikasi yang dapat mendeteksi ada atau tidaknya perangkat listrik pada citra X-ray bagasi</p></li>
<li><p>Menyediakan sistem yang dapat diintegrasikan ke aplikasi (deployment)</p></li>
<li><p>Memberikan confidence score dan penjelasan model (explainability) untuk mendukung pengambilan keputusan</p></li>
</ul>
</section>
<section id="definisi-masalah">
<h2>Definisi Masalah<a class="headerlink" href="#definisi-masalah" title="Link to this heading">#</a></h2>
<p>Masalah diformulasikan sebagai binary classification:</p>
<p>0 → Tidak terdapat perangkat listrik</p>
<p>1 → Terdapat perangkat listrik</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data-understanding">
<h1>Data Understanding<a class="headerlink" href="#data-understanding" title="Link to this heading">#</a></h1>
<section id="deskripsi-dataset">
<h2>Deskripsi Dataset<a class="headerlink" href="#deskripsi-dataset" title="Link to this heading">#</a></h2>
<p>Dataset yang digunakan adalah ElectricDeviceDetection dengan format .arff, terdiri dari:</p>
<ul class="simple">
<li><p>256 fitur numerik (att1 – att256)</p></li>
<li><p>1 label target (target)</p></li>
</ul>
<p>Setiap sampel merepresentasikan histogram intensitas voxel dari citra X-ray 3D yang telah diproyeksikan menjadi sinyal 1D.</p>
<p>Mengapa Dataset Termasuk Data Time Series?</p>
<p>Meskipun bukan time series dalam arti waktu eksplisit, dataset ini dipandang sebagai data time series karena:</p>
<ul class="simple">
<li><p>Fitur att1 hingga att256 merepresentasikan urutan bin histogram</p></li>
<li><p>Setiap fitur memiliki urutan tetap dan saling bergantung</p></li>
<li><p>Pola antar-bin membentuk sinyal 1D berurutan</p></li>
</ul>
<p>Karena sifat ini:</p>
<ul class="simple">
<li><p>Model seperti DTW, CNN-1D, dan PCA berbasis urutan menjadi relevan</p></li>
<li><p>Visualisasi dilakukan dengan line plot, bukan scatter antar fitur</p></li>
</ul>
</section>
<section id="load-library">
<h2>Load Library<a class="headerlink" href="#load-library" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.io</span><span class="w"> </span><span class="kn">import</span> <span class="n">arff</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-data-konversi-label">
<h2>LOAD DATA &amp; KONVERSI LABEL<a class="headerlink" href="#load-data-konversi-label" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load training data</span>
<span class="n">data_train</span><span class="p">,</span> <span class="n">meta_train</span> <span class="o">=</span> <span class="n">arff</span><span class="o">.</span><span class="n">loadarff</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/dataset/ElectricDeviceDetection/ElectricDeviceDetection_TRAIN.arff&quot;</span><span class="p">)</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>

<span class="c1"># Load testing data</span>
<span class="n">data_test</span><span class="p">,</span> <span class="n">meta_test</span> <span class="o">=</span> <span class="n">arff</span><span class="o">.</span><span class="n">loadarff</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/dataset/ElectricDeviceDetection/ElectricDeviceDetection_TEST.arff&quot;</span><span class="p">)</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape Train:&quot;</span><span class="p">,</span> <span class="n">df_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape Test :&quot;</span><span class="p">,</span> <span class="n">df_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Load training data</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">data_train</span><span class="p">,</span> <span class="n">meta_train</span> <span class="o">=</span> <span class="n">arff</span><span class="o">.</span><span class="n">loadarff</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/dataset/ElectricDeviceDetection/ElectricDeviceDetection_TRAIN.arff&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># Load testing data</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\scipy\io\arff\_arffread.py:800,</span> in <span class="ni">loadarff</span><span class="nt">(f)</span>
<span class="g g-Whitespace">    </span><span class="mi">798</span>     <span class="n">ofile</span> <span class="o">=</span> <span class="n">f</span>
<span class="g g-Whitespace">    </span><span class="mi">799</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">800</span>     <span class="n">ofile</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">801</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">802</span>     <span class="k">return</span> <span class="n">_loadarff</span><span class="p">(</span><span class="n">ofile</span><span class="p">)</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;/content/drive/MyDrive/dataset/ElectricDeviceDetection/ElectricDeviceDetection_TRAIN.arff&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="cek-struktur-data">
<h2>CEK STRUKTUR DATA<a class="headerlink" href="#cek-struktur-data" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Konversi target dari byte ke int</span>
<span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">decode</span><span class="p">()))</span>
<span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>  <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">decode</span><span class="p">()))</span>

<span class="c1"># Info struktur data</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO TRAIN&quot;</span><span class="p">)</span>
<span class="n">df_train</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">INFO TEST&quot;</span><span class="p">)</span>
<span class="n">df_test</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO TRAIN
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 624 entries, 0 to 623
Columns: 257 entries, att1 to target
dtypes: float64(256), int64(1)
memory usage: 1.2 MB

INFO TEST
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 3768 entries, 0 to 3767
Columns: 257 entries, att1 to target
dtypes: float64(256), int64(1)
memory usage: 7.4 MB
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape Train:&quot;</span><span class="p">,</span> <span class="n">df_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape Test :&quot;</span><span class="p">,</span> <span class="n">df_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape Train: (624, 257)
Shape Test : (3768, 257)
</pre></div>
</div>
</div>
</div>
</section>
<section id="distribusi-kelas">
<h2>DISTRIBUSI KELAS<a class="headerlink" href="#distribusi-kelas" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">class_counts</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_counts</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">class_counts</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribusi Kelas&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Kelas (0 = No Device, 1 = Electric Device)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Jumlah Data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>target
0    543
1     81
Name: count, dtype: int64
</pre></div>
</div>
<img alt="_images/2069f2fa830973fcd1ad82f4f9661ecb641738f2fb49cac1e464c0f4ebfb85ad.png" src="_images/2069f2fa830973fcd1ad82f4f9661ecb641738f2fb49cac1e464c0f4ebfb85ad.png" />
</div>
</div>
</section>
<section id="missing-value-check">
<h2>MISSING VALUE CHECK<a class="headerlink" href="#missing-value-check" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">missing_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">missing_test</span>  <span class="o">=</span> <span class="n">df_test</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing Train:&quot;</span><span class="p">,</span> <span class="n">missing_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing Test :&quot;</span><span class="p">,</span> <span class="n">missing_test</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">df_train</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribusi Missing Value per Fitur (Train)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Jumlah Missing&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Missing Train: 0
Missing Test : 0
</pre></div>
</div>
<img alt="_images/27ed29e55e8bec3cc8dc5613171a56a168b45388a7c9f7f04c0f545f5fc2e887.png" src="_images/27ed29e55e8bec3cc8dc5613171a56a168b45388a7c9f7f04c0f545f5fc2e887.png" />
</div>
</div>
</section>
<section id="statistik-deskriptif">
<h2>STATISTIK DESKRIPTIF<a class="headerlink" href="#statistik-deskriptif" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">])</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-2c1e1e1e-71ae-4cb5-ad2f-25897ed02e7f" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>att1</th>
      <td>624.0</td>
      <td>2.836538</td>
      <td>40.269345</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>900.0</td>
    </tr>
    <tr>
      <th>att2</th>
      <td>624.0</td>
      <td>2.506410</td>
      <td>36.661875</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>867.0</td>
    </tr>
    <tr>
      <th>att3</th>
      <td>624.0</td>
      <td>4.232372</td>
      <td>77.784648</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1920.0</td>
    </tr>
    <tr>
      <th>att4</th>
      <td>624.0</td>
      <td>3.451923</td>
      <td>48.111904</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1126.0</td>
    </tr>
    <tr>
      <th>att5</th>
      <td>624.0</td>
      <td>4.493590</td>
      <td>53.190532</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1099.0</td>
    </tr>
    <tr>
      <th>att6</th>
      <td>624.0</td>
      <td>6.312500</td>
      <td>67.792953</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1053.0</td>
    </tr>
    <tr>
      <th>att7</th>
      <td>624.0</td>
      <td>1865.073718</td>
      <td>17455.608429</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>288432.0</td>
    </tr>
    <tr>
      <th>att8</th>
      <td>624.0</td>
      <td>3697.051282</td>
      <td>33494.490772</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>566847.0</td>
    </tr>
    <tr>
      <th>att9</th>
      <td>624.0</td>
      <td>3106.697115</td>
      <td>25882.866378</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>451346.0</td>
    </tr>
    <tr>
      <th>att10</th>
      <td>624.0</td>
      <td>3044.035256</td>
      <td>21357.493766</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>384607.0</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-2c1e1e1e-71ae-4cb5-ad2f-25897ed02e7f')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-2c1e1e1e-71ae-4cb5-ad2f-25897ed02e7f button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-2c1e1e1e-71ae-4cb5-ad2f-25897ed02e7f');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-e02280e3-de13-48d3-b737-c93093cfe94c">
      <button class="colab-df-quickchart" onclick="quickchart('df-e02280e3-de13-48d3-b737-c93093cfe94c')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-e02280e3-de13-48d3-b737-c93093cfe94c button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Rata-rata Nilai Setiap Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Index Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Nilai Rata-rata&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5b18e3efd8db80ad72e080b27389f7a3b2b217d1fef6ab7dc21f9013483578bd.png" src="_images/5b18e3efd8db80ad72e080b27389f7a3b2b217d1fef6ab7dc21f9013483578bd.png" />
</div>
</div>
</section>
<section id="distribusi-nilai-fitur-global">
<h2>DISTRIBUSI NILAI FITUR (GLOBAL)<a class="headerlink" href="#distribusi-nilai-fitur-global" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribusi Global Nilai Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Nilai&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Frekuensi&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1608ce0ee10e0af07874104bcba8ed577f6351d261edf47a14284cdf553bfb18.png" src="_images/1608ce0ee10e0af07874104bcba8ed577f6351d261edf47a14284cdf553bfb18.png" />
</div>
</div>
</section>
<section id="visualisasi-1-sampel">
<h2>VISUALISASI 1 SAMPEL<a class="headerlink" href="#visualisasi-1-sampel" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Histogram Intensitas - 1 Sampel&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Index Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Nilai Intensitas&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9cdaa794f302eb8ae181674cd1ab5dab6b1f3b6f3caccf74b07d7ae909ce1b29.png" src="_images/9cdaa794f302eb8ae181674cd1ab5dab6b1f3b6f3caccf74b07d7ae909ce1b29.png" />
</div>
</div>
</section>
<section id="perbandingan-rata-rata-per-kelas">
<h2>PERBANDINGAN RATA-RATA PER KELAS<a class="headerlink" href="#perbandingan-rata-rata-per-kelas" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>

<span class="n">mean_no_device</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">mean_device</span>    <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mean_no_device</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;No Device (0)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mean_device</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Electric Device (1)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Perbandingan Rata-rata Histogram per Kelas&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Index Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Nilai&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b9a8c0778a7dded532500e8b247f6b62bc496c33dcb0ffe4978e57ec530fadd3.png" src="_images/b9a8c0778a7dded532500e8b247f6b62bc496c33dcb0ffe4978e57ec530fadd3.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="heatmap-korelasi">
<h1>HEATMAP KORELASI<a class="headerlink" href="#heatmap-korelasi" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">20</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Heatmap Korelasi 20 Fitur Pertama&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/161b02ab8d0168c980c7a02ce5e76546e643f9d89ab1472941903731c070d343.png" src="_images/161b02ab8d0168c980c7a02ce5e76546e643f9d89ab1472941903731c070d343.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="outlier-detection-z-score">
<h1>OUTLIER DETECTION (Z-SCORE)<a class="headerlink" href="#outlier-detection-z-score" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">zscore</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Hitung z-score</span>
<span class="n">z_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">zscore</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>

<span class="c1"># Outlier PER FITUR (sum per kolom / per fitur)</span>
<span class="n">outliers_per_feature</span> <span class="o">=</span> <span class="p">(</span><span class="n">z_scores</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Total outlier keseluruhan</span>
<span class="n">total_outliers</span> <span class="o">=</span> <span class="n">outliers_per_feature</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total Outlier:&quot;</span><span class="p">,</span> <span class="n">total_outliers</span><span class="p">)</span>

<span class="c1"># Visualisasi jumlah outlier per fitur</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">outliers_per_feature</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Jumlah Outlier per Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Index Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Jumlah Outlier&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total Outlier: 2990
</pre></div>
</div>
<img alt="_images/84646fc239d617278a8016a7fefe667aebea726c4057a5e0b4ac4ca5e2d77da4.png" src="_images/84646fc239d617278a8016a7fefe667aebea726c4057a5e0b4ac4ca5e2d77da4.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">outlier_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Fitur&quot;</span><span class="p">:</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="s2">&quot;Jumlah_Outlier&quot;</span><span class="p">:</span> <span class="n">outliers_per_feature</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Jumlah_Outlier&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">outlier_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-32a67ed7-f94d-4f31-880a-0f12d0dd7754" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fitur</th>
      <th>Jumlah_Outlier</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>34</th>
      <td>att35</td>
      <td>23</td>
    </tr>
    <tr>
      <th>33</th>
      <td>att34</td>
      <td>21</td>
    </tr>
    <tr>
      <th>73</th>
      <td>att74</td>
      <td>21</td>
    </tr>
    <tr>
      <th>31</th>
      <td>att32</td>
      <td>20</td>
    </tr>
    <tr>
      <th>35</th>
      <td>att36</td>
      <td>20</td>
    </tr>
    <tr>
      <th>36</th>
      <td>att37</td>
      <td>20</td>
    </tr>
    <tr>
      <th>72</th>
      <td>att73</td>
      <td>20</td>
    </tr>
    <tr>
      <th>32</th>
      <td>att33</td>
      <td>20</td>
    </tr>
    <tr>
      <th>74</th>
      <td>att75</td>
      <td>20</td>
    </tr>
    <tr>
      <th>75</th>
      <td>att76</td>
      <td>19</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-32a67ed7-f94d-4f31-880a-0f12d0dd7754')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-32a67ed7-f94d-4f31-880a-0f12d0dd7754 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-32a67ed7-f94d-4f31-880a-0f12d0dd7754');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-59f14ba5-c079-462d-8778-663024348514">
      <button class="colab-df-quickchart" onclick="quickchart('df-59f14ba5-c079-462d-8778-663024348514')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-59f14ba5-c079-462d-8778-663024348514 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="variansi-fitur">
<h1>VARIANSI FITUR<a class="headerlink" href="#variansi-fitur" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">variances</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">variances</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Variansi Setiap Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Index Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Variansi&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/cd7b76449e28513e2f817ab12c4598cc884e99f1d34819ae086cc7e433e1b8dd.png" src="_images/cd7b76449e28513e2f817ab12c4598cc884e99f1d34819ae086cc7e433e1b8dd.png" />
</div>
</div>
<section id="temuan-awal-dari-eda">
<h2>Temuan Awal dari EDA<a class="headerlink" href="#temuan-awal-dari-eda" title="Link to this heading">#</a></h2>
<p>Berdasarkan eksplorasi data:</p>
<ul class="simple">
<li><p>Dataset tidak memiliki missing value</p></li>
<li><p>Distribusi kelas tidak seimbang (kelas non-device lebih dominan)</p></li>
<li><p>Nilai fitur memiliki:</p>
<ul>
<li><p>Skewness tinggi</p></li>
<li><p>Banyak nilai nol</p></li>
<li><p>Rentang nilai sangat besar (outlier alami)</p></li>
</ul>
</li>
</ul>
<p>Outlier tidak dihapus, karena:</p>
<ul class="simple">
<li><p>Outlier merupakan bagian dari pola fisik citra X-ray</p></li>
<li><p>Intensitas tinggi bisa menandakan material padat atau perangkat listrik</p></li>
<li><p>Model pohon dan boosting cukup robust terhadap outlier</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data-preparation">
<h1>Data Preparation<a class="headerlink" href="#data-preparation" title="Link to this heading">#</a></h1>
<section id="preprocessing">
<h2>PREPROCESSING<a class="headerlink" href="#preprocessing" title="Link to this heading">#</a></h2>
<section id="penggabungan-dataset">
<h3>Penggabungan Dataset<a class="headerlink" href="#penggabungan-dataset" title="Link to this heading">#</a></h3>
<p>Dataset TRAIN dan TEST digabung, kemudian dibagi ulang menjadi:</p>
<ul class="simple">
<li><p>60% Training</p></li>
<li><p>20% Testing (Evaluasi Model)</p></li>
<li><p>20% Deployment Testing</p></li>
</ul>
<p>Tujuan:</p>
<ul class="simple">
<li><p>Menghindari bias pembagian awal</p></li>
<li><p>Menyediakan data realistis untuk pengujian aplikasi</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pisahkan fitur dan target</span>
<span class="c1"># Gabungkan dataset</span>
<span class="n">df_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_all</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_all</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># 60% training</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_temp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_temp</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># 20% test model, 20% deployment</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">X_deploy</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_deploy</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_temp</span><span class="p">,</span> <span class="n">y_temp</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="n">y_temp</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_train:&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_test :&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>X_train: (2635, 256)
X_test : (878, 256)
</pre></div>
</div>
</div>
</div>
</section>
<section id="tahapan-preprocessing">
<h3>Tahapan Preprocessing<a class="headerlink" href="#tahapan-preprocessing" title="Link to this heading">#</a></h3>
<p>Langkah preprocessing yang dilakukan:</p>
<ol class="arabic simple">
<li><p>Handling Missing Value</p></li>
</ol>
<ul class="simple">
<li><p>Tidak ditemukan missing value, namun tetap disiapkan pengamanan (fillna(0))</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Outlier Handling</p></li>
</ol>
<ul class="simple">
<li><p>Menggunakan clipping quantile 1%–99%</p></li>
<li><p>Mengurangi ekstrem tanpa menghilangkan informasi penting</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Feature Scaling</p></li>
</ol>
<ul class="simple">
<li><p>Menggunakan StandardScaler</p></li>
<li><p>Penting untuk PCA, SVM, dan CNN</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Dimensionality Reduction (PCA)</p></li>
</ol>
<ul class="simple">
<li><p>PCA dengan 95% explained variance</p></li>
<li><p>Dimensi berkurang dari 256 → 22 fitur</p></li>
<li><p>Mengurangi noise dan multikolinearitas</p></li>
</ul>
<section id="validasi-penanganan-missing-value">
<h4>VALIDASI &amp; PENANGANAN MISSING VALUE<a class="headerlink" href="#validasi-penanganan-missing-value" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing X_train:&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing X_test :&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="c1"># Jika ada missing value (antisipasi keamanan)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_test</span>  <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Missing X_train: 0
Missing X_test : 0
</pre></div>
</div>
</div>
</div>
</section>
<section id="handling-outlier-dengan-clipping">
<h4>HANDLING OUTLIER DENGAN CLIPPING<a class="headerlink" href="#handling-outlier-dengan-clipping" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_clipped</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span>
                               <span class="n">upper</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.99</span><span class="p">),</span>
                               <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_test_clipped</span>  <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span>
                              <span class="n">upper</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.99</span><span class="p">),</span>
                              <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-scaling">
<h4>FEATURE SCALING<a class="headerlink" href="#feature-scaling" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_clipped</span><span class="p">)</span>
<span class="n">X_test_scaled</span>  <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_clipped</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2635, 256) (878, 256)
</pre></div>
</div>
</div>
</div>
</section>
<section id="pca-reduksi-dimensi">
<h4>PCA – REDUKSI DIMENSI<a class="headerlink" href="#pca-reduksi-dimensi" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">X_test_pca</span>  <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">X_deploy_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_deploy</span><span class="p">)</span>
<span class="n">X_deploy_pca</span>    <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_deploy_scaled</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sebelum PCA:&quot;</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sesudah PCA :&quot;</span><span class="p">,</span> <span class="n">X_train_pca</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sebelum PCA: 256
Sesudah PCA : 22
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pca_2d</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_train_2d</span> <span class="o">=</span> <span class="n">pca_2d</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_2d</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_2d</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;No Device&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_2d</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_2d</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Electric Device&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Visualisasi PCA 2D Dataset&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;PC1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;PC2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/46867b2c0a2cbb08288793821ff90986ae6975d5b12d6c2077f1449e6c108783.png" src="_images/46867b2c0a2cbb08288793821ff90986ae6975d5b12d6c2077f1449e6c108783.png" />
</div>
</div>
</section>
</section>
<section id="final-output-untuk-modeling">
<h3>FINAL OUTPUT UNTUK MODELING<a class="headerlink" href="#final-output-untuk-modeling" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_final</span> <span class="o">=</span> <span class="n">X_train_pca</span>
<span class="n">X_test_final</span>  <span class="o">=</span> <span class="n">X_test_pca</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final Train Shape:&quot;</span><span class="p">,</span> <span class="n">X_train_final</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final Test  Shape:&quot;</span><span class="p">,</span> <span class="n">X_test_final</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label Train:&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label Test :&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Final Train Shape: (2635, 22)
Final Test  Shape: (878, 22)
Label Train: (2635,)
Label Test : (878,)
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="modeling">
<h1>Modeling<a class="headerlink" href="#modeling" title="Link to this heading">#</a></h1>
<p>Pada tahap modeling, beberapa algoritma machine learning diuji untuk membandingkan performa klasifikasi, yaitu:</p>
<ol class="arabic simple">
<li><p>Random Forest : Robust, baseline kuat</p></li>
<li><p>Support Vector Machine (SVM) : Cocok untuk data high-dimensional</p></li>
<li><p>XGBoost : Menangani non-linear &amp; imbalance dengan baik</p></li>
<li><p>CNN 1D : Memanfaatkan sifat sekuensial histogram</p></li>
</ol>
<p>Pemilihan model dilakukan untuk mengevaluasi berbagai pendekatan:</p>
<ul class="simple">
<li><p>Tree-based models untuk menangkap hubungan non-linear</p></li>
<li><p>Margin-based model (SVM) untuk data berdimensi tinggi</p></li>
<li><p>Time-series inspired method (DTW)</p></li>
<li><p>Deep learning (CNN 1D)</p></li>
</ul>
<p>Pemilihan model terbaik didasarkan pada kemampuan mendeteksi perangkat listrik secara seimbang, bukan sekadar akurasi keseluruhan.</p>
<p>RANDOM FOREST</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">n_trees</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">warm_start</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span>
<span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_trees</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training Random Forest&quot;</span><span class="p">):</span>
    <span class="n">rf</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_final</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">total_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="n">rf_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_final</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Random Forest Training Time: </span><span class="si">{</span><span class="n">total_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Random Forest:   0%|          | 0/300 [00:00&lt;?, ?it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:   3%|▎         | 8/300 [00:00&lt;00:03, 73.91it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:   6%|▌         | 17/300 [00:00&lt;00:03, 79.08it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:   8%|▊         | 25/300 [00:00&lt;00:03, 75.53it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  11%|█▏        | 34/300 [00:00&lt;00:03, 78.01it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  14%|█▍        | 43/300 [00:00&lt;00:03, 79.85it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  17%|█▋        | 51/300 [00:00&lt;00:03, 79.36it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  20%|██        | 60/300 [00:00&lt;00:02, 80.86it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  23%|██▎       | 69/300 [00:00&lt;00:02, 80.80it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  26%|██▌       | 78/300 [00:00&lt;00:02, 80.69it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  29%|██▉       | 87/300 [00:01&lt;00:02, 77.64it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  32%|███▏      | 95/300 [00:01&lt;00:02, 78.07it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  34%|███▍      | 103/300 [00:01&lt;00:02, 78.02it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  37%|███▋      | 111/300 [00:01&lt;00:02, 77.40it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  40%|███▉      | 119/300 [00:01&lt;00:02, 77.28it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  42%|████▏     | 127/300 [00:01&lt;00:02, 76.76it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  45%|████▌     | 135/300 [00:01&lt;00:02, 77.14it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  48%|████▊     | 143/300 [00:01&lt;00:02, 77.57it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  50%|█████     | 151/300 [00:01&lt;00:01, 77.38it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  53%|█████▎    | 159/300 [00:02&lt;00:01, 77.80it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  56%|█████▌    | 167/300 [00:02&lt;00:01, 74.68it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  58%|█████▊    | 175/300 [00:02&lt;00:01, 75.84it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  61%|██████    | 183/300 [00:02&lt;00:01, 76.52it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  64%|██████▎   | 191/300 [00:02&lt;00:01, 75.31it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  66%|██████▋   | 199/300 [00:02&lt;00:01, 76.21it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  69%|██████▉   | 207/300 [00:02&lt;00:01, 75.59it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  72%|███████▏  | 215/300 [00:02&lt;00:01, 74.71it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  74%|███████▍  | 223/300 [00:02&lt;00:01, 74.00it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  77%|███████▋  | 231/300 [00:03&lt;00:00, 71.59it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  80%|███████▉  | 239/300 [00:03&lt;00:00, 70.23it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  82%|████████▏ | 247/300 [00:03&lt;00:00, 69.74it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  85%|████████▌ | 255/300 [00:03&lt;00:00, 71.00it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  88%|████████▊ | 263/300 [00:03&lt;00:00, 70.63it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  90%|█████████ | 271/300 [00:03&lt;00:00, 68.10it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  93%|█████████▎| 279/300 [00:03&lt;00:00, 69.44it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  95%|█████████▌| 286/300 [00:03&lt;00:00, 68.41it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest:  98%|█████████▊| 294/300 [00:03&lt;00:00, 69.58it/s]/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets &quot;balanced&quot; or &quot;balanced_subsample&quot; are not recommended for warm_start if the fitted data differs from the full dataset. In order to use &quot;balanced&quot; weights, use compute_class_weight (&quot;balanced&quot;, classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
Training Random Forest: 100%|██████████| 300/300 [00:04&lt;00:00, 74.54it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest Training Time: 4.03 seconds
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Random Forest Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest Accuracy: 0.9111617312072893
              precision    recall  f1-score   support

           0       0.92      0.98      0.95       756
           1       0.78      0.50      0.61       122

    accuracy                           0.91       878
   macro avg       0.85      0.74      0.78       878
weighted avg       0.90      0.91      0.90       878

[[739  17]
 [ 61  61]]
</pre></div>
</div>
</div>
</div>
<p>SVM (Support Vector Machine)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span>
    <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span>
    <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_final</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">total_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="n">svm_pred</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_final</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SVM Training Time: </span><span class="si">{</span><span class="n">total_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVM Training Time: 1.03 seconds
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;SVM Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVM Accuracy: 0.8667425968109339
              precision    recall  f1-score   support

           0       0.95      0.89      0.92       756
           1       0.52      0.70      0.59       122

    accuracy                           0.87       878
   macro avg       0.73      0.80      0.76       878
weighted avg       0.89      0.87      0.87       878

[[676  80]
 [ 37  85]]
</pre></div>
</div>
</div>
</div>
<p>XGBOOST</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">subsample</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">objective</span><span class="o">=</span><span class="s2">&quot;binary:logistic&quot;</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train_final</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
    <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_test_final</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">total_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="n">xgb_pred</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_final</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">XGBoost Training Time: </span><span class="si">{</span><span class="n">total_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0]	validation_0-logloss:0.38684
[1]	validation_0-logloss:0.37205
[2]	validation_0-logloss:0.36082
[3]	validation_0-logloss:0.35220
[4]	validation_0-logloss:0.34251
[5]	validation_0-logloss:0.33422
[6]	validation_0-logloss:0.32683
[7]	validation_0-logloss:0.31999
[8]	validation_0-logloss:0.31354
[9]	validation_0-logloss:0.30850
[10]	validation_0-logloss:0.30294
[11]	validation_0-logloss:0.29763
[12]	validation_0-logloss:0.29220
[13]	validation_0-logloss:0.28835
[14]	validation_0-logloss:0.28590
[15]	validation_0-logloss:0.28255
[16]	validation_0-logloss:0.27830
[17]	validation_0-logloss:0.27517
[18]	validation_0-logloss:0.27218
[19]	validation_0-logloss:0.26905
[20]	validation_0-logloss:0.26612
[21]	validation_0-logloss:0.26293
[22]	validation_0-logloss:0.26039
[23]	validation_0-logloss:0.25836
[24]	validation_0-logloss:0.25634
[25]	validation_0-logloss:0.25475
[26]	validation_0-logloss:0.25315
[27]	validation_0-logloss:0.25080
[28]	validation_0-logloss:0.24931
[29]	validation_0-logloss:0.24776
[30]	validation_0-logloss:0.24634
[31]	validation_0-logloss:0.24412
[32]	validation_0-logloss:0.24296
[33]	validation_0-logloss:0.24231
[34]	validation_0-logloss:0.24057
[35]	validation_0-logloss:0.23906
[36]	validation_0-logloss:0.23850
[37]	validation_0-logloss:0.23767
[38]	validation_0-logloss:0.23662
[39]	validation_0-logloss:0.23595
[40]	validation_0-logloss:0.23476
[41]	validation_0-logloss:0.23413
[42]	validation_0-logloss:0.23328
[43]	validation_0-logloss:0.23250
[44]	validation_0-logloss:0.23218
[45]	validation_0-logloss:0.23156
[46]	validation_0-logloss:0.23074
[47]	validation_0-logloss:0.22985
[48]	validation_0-logloss:0.22938
[49]	validation_0-logloss:0.22934
[50]	validation_0-logloss:0.22899
[51]	validation_0-logloss:0.22882
[52]	validation_0-logloss:0.22863
[53]	validation_0-logloss:0.22835
[54]	validation_0-logloss:0.22752
[55]	validation_0-logloss:0.22755
[56]	validation_0-logloss:0.22736
[57]	validation_0-logloss:0.22715
[58]	validation_0-logloss:0.22680
[59]	validation_0-logloss:0.22650
[60]	validation_0-logloss:0.22632
[61]	validation_0-logloss:0.22568
[62]	validation_0-logloss:0.22532
[63]	validation_0-logloss:0.22525
[64]	validation_0-logloss:0.22507
[65]	validation_0-logloss:0.22441
[66]	validation_0-logloss:0.22454
[67]	validation_0-logloss:0.22438
[68]	validation_0-logloss:0.22472
[69]	validation_0-logloss:0.22437
[70]	validation_0-logloss:0.22404
[71]	validation_0-logloss:0.22401
[72]	validation_0-logloss:0.22375
[73]	validation_0-logloss:0.22327
[74]	validation_0-logloss:0.22362
[75]	validation_0-logloss:0.22339
[76]	validation_0-logloss:0.22342
[77]	validation_0-logloss:0.22326
[78]	validation_0-logloss:0.22327
[79]	validation_0-logloss:0.22310
[80]	validation_0-logloss:0.22288
[81]	validation_0-logloss:0.22271
[82]	validation_0-logloss:0.22249
[83]	validation_0-logloss:0.22232
[84]	validation_0-logloss:0.22239
[85]	validation_0-logloss:0.22246
[86]	validation_0-logloss:0.22213
[87]	validation_0-logloss:0.22215
[88]	validation_0-logloss:0.22247
[89]	validation_0-logloss:0.22245
[90]	validation_0-logloss:0.22248
[91]	validation_0-logloss:0.22265
[92]	validation_0-logloss:0.22254
[93]	validation_0-logloss:0.22250
[94]	validation_0-logloss:0.22243
[95]	validation_0-logloss:0.22234
[96]	validation_0-logloss:0.22262
[97]	validation_0-logloss:0.22292
[98]	validation_0-logloss:0.22296
[99]	validation_0-logloss:0.22288
[100]	validation_0-logloss:0.22302
[101]	validation_0-logloss:0.22318
[102]	validation_0-logloss:0.22300
[103]	validation_0-logloss:0.22337
[104]	validation_0-logloss:0.22346
[105]	validation_0-logloss:0.22345
[106]	validation_0-logloss:0.22346
[107]	validation_0-logloss:0.22371
[108]	validation_0-logloss:0.22376
[109]	validation_0-logloss:0.22397
[110]	validation_0-logloss:0.22396
[111]	validation_0-logloss:0.22388
[112]	validation_0-logloss:0.22385
[113]	validation_0-logloss:0.22436
[114]	validation_0-logloss:0.22455
[115]	validation_0-logloss:0.22478
[116]	validation_0-logloss:0.22467
[117]	validation_0-logloss:0.22466
[118]	validation_0-logloss:0.22451
[119]	validation_0-logloss:0.22452
[120]	validation_0-logloss:0.22474
[121]	validation_0-logloss:0.22449
[122]	validation_0-logloss:0.22427
[123]	validation_0-logloss:0.22441
[124]	validation_0-logloss:0.22431
[125]	validation_0-logloss:0.22449
[126]	validation_0-logloss:0.22466
[127]	validation_0-logloss:0.22443
[128]	validation_0-logloss:0.22471
[129]	validation_0-logloss:0.22483
[130]	validation_0-logloss:0.22515
[131]	validation_0-logloss:0.22522
[132]	validation_0-logloss:0.22551
[133]	validation_0-logloss:0.22566
[134]	validation_0-logloss:0.22585
[135]	validation_0-logloss:0.22580
[136]	validation_0-logloss:0.22565
[137]	validation_0-logloss:0.22545
[138]	validation_0-logloss:0.22554
[139]	validation_0-logloss:0.22574
[140]	validation_0-logloss:0.22564
[141]	validation_0-logloss:0.22571
[142]	validation_0-logloss:0.22595
[143]	validation_0-logloss:0.22610
[144]	validation_0-logloss:0.22632
[145]	validation_0-logloss:0.22676
[146]	validation_0-logloss:0.22698
[147]	validation_0-logloss:0.22701
[148]	validation_0-logloss:0.22726
[149]	validation_0-logloss:0.22724
[150]	validation_0-logloss:0.22735
[151]	validation_0-logloss:0.22751
[152]	validation_0-logloss:0.22779
[153]	validation_0-logloss:0.22794
[154]	validation_0-logloss:0.22802
[155]	validation_0-logloss:0.22792
[156]	validation_0-logloss:0.22784
[157]	validation_0-logloss:0.22805
[158]	validation_0-logloss:0.22820
[159]	validation_0-logloss:0.22830
[160]	validation_0-logloss:0.22854
[161]	validation_0-logloss:0.22882
[162]	validation_0-logloss:0.22877
[163]	validation_0-logloss:0.22898
[164]	validation_0-logloss:0.22925
[165]	validation_0-logloss:0.22925
[166]	validation_0-logloss:0.22926
[167]	validation_0-logloss:0.22945
[168]	validation_0-logloss:0.22970
[169]	validation_0-logloss:0.22999
[170]	validation_0-logloss:0.23026
[171]	validation_0-logloss:0.23028
[172]	validation_0-logloss:0.23061
[173]	validation_0-logloss:0.23062
[174]	validation_0-logloss:0.23071
[175]	validation_0-logloss:0.23079
[176]	validation_0-logloss:0.23111
[177]	validation_0-logloss:0.23108
[178]	validation_0-logloss:0.23109
[179]	validation_0-logloss:0.23123
[180]	validation_0-logloss:0.23131
[181]	validation_0-logloss:0.23158
[182]	validation_0-logloss:0.23175
[183]	validation_0-logloss:0.23191
[184]	validation_0-logloss:0.23208
[185]	validation_0-logloss:0.23201
[186]	validation_0-logloss:0.23206
[187]	validation_0-logloss:0.23196
[188]	validation_0-logloss:0.23203
[189]	validation_0-logloss:0.23223
[190]	validation_0-logloss:0.23218
[191]	validation_0-logloss:0.23230
[192]	validation_0-logloss:0.23254
[193]	validation_0-logloss:0.23280
[194]	validation_0-logloss:0.23305
[195]	validation_0-logloss:0.23313
[196]	validation_0-logloss:0.23324
[197]	validation_0-logloss:0.23322
[198]	validation_0-logloss:0.23331
[199]	validation_0-logloss:0.23363
[200]	validation_0-logloss:0.23367
[201]	validation_0-logloss:0.23371
[202]	validation_0-logloss:0.23412
[203]	validation_0-logloss:0.23427
[204]	validation_0-logloss:0.23463
[205]	validation_0-logloss:0.23485
[206]	validation_0-logloss:0.23513
[207]	validation_0-logloss:0.23523
[208]	validation_0-logloss:0.23563
[209]	validation_0-logloss:0.23598
[210]	validation_0-logloss:0.23589
[211]	validation_0-logloss:0.23603
[212]	validation_0-logloss:0.23619
[213]	validation_0-logloss:0.23616
[214]	validation_0-logloss:0.23616
[215]	validation_0-logloss:0.23630
[216]	validation_0-logloss:0.23632
[217]	validation_0-logloss:0.23656
[218]	validation_0-logloss:0.23679
[219]	validation_0-logloss:0.23691
[220]	validation_0-logloss:0.23690
[221]	validation_0-logloss:0.23700
[222]	validation_0-logloss:0.23703
[223]	validation_0-logloss:0.23748
[224]	validation_0-logloss:0.23775
[225]	validation_0-logloss:0.23799
[226]	validation_0-logloss:0.23799
[227]	validation_0-logloss:0.23839
[228]	validation_0-logloss:0.23870
[229]	validation_0-logloss:0.23866
[230]	validation_0-logloss:0.23861
[231]	validation_0-logloss:0.23869
[232]	validation_0-logloss:0.23882
[233]	validation_0-logloss:0.23891
[234]	validation_0-logloss:0.23895
[235]	validation_0-logloss:0.23915
[236]	validation_0-logloss:0.23915
[237]	validation_0-logloss:0.23931
[238]	validation_0-logloss:0.23922
[239]	validation_0-logloss:0.23939
[240]	validation_0-logloss:0.23957
[241]	validation_0-logloss:0.23961
[242]	validation_0-logloss:0.23975
[243]	validation_0-logloss:0.23963
[244]	validation_0-logloss:0.23961
[245]	validation_0-logloss:0.23981
[246]	validation_0-logloss:0.23983
[247]	validation_0-logloss:0.23976
[248]	validation_0-logloss:0.23993
[249]	validation_0-logloss:0.24013
[250]	validation_0-logloss:0.24025
[251]	validation_0-logloss:0.24036
[252]	validation_0-logloss:0.24056
[253]	validation_0-logloss:0.24080
[254]	validation_0-logloss:0.24087
[255]	validation_0-logloss:0.24096
[256]	validation_0-logloss:0.24085
[257]	validation_0-logloss:0.24099
[258]	validation_0-logloss:0.24111
[259]	validation_0-logloss:0.24151
[260]	validation_0-logloss:0.24163
[261]	validation_0-logloss:0.24188
[262]	validation_0-logloss:0.24214
[263]	validation_0-logloss:0.24201
[264]	validation_0-logloss:0.24212
[265]	validation_0-logloss:0.24241
[266]	validation_0-logloss:0.24257
[267]	validation_0-logloss:0.24250
[268]	validation_0-logloss:0.24262
[269]	validation_0-logloss:0.24278
[270]	validation_0-logloss:0.24288
[271]	validation_0-logloss:0.24293
[272]	validation_0-logloss:0.24308
[273]	validation_0-logloss:0.24323
[274]	validation_0-logloss:0.24334
[275]	validation_0-logloss:0.24356
[276]	validation_0-logloss:0.24359
[277]	validation_0-logloss:0.24384
[278]	validation_0-logloss:0.24400
[279]	validation_0-logloss:0.24396
[280]	validation_0-logloss:0.24423
[281]	validation_0-logloss:0.24422
[282]	validation_0-logloss:0.24423
[283]	validation_0-logloss:0.24433
[284]	validation_0-logloss:0.24420
[285]	validation_0-logloss:0.24423
[286]	validation_0-logloss:0.24430
[287]	validation_0-logloss:0.24429
[288]	validation_0-logloss:0.24424
[289]	validation_0-logloss:0.24440
[290]	validation_0-logloss:0.24446
[291]	validation_0-logloss:0.24454
[292]	validation_0-logloss:0.24450
[293]	validation_0-logloss:0.24443
[294]	validation_0-logloss:0.24450
[295]	validation_0-logloss:0.24475
[296]	validation_0-logloss:0.24470
[297]	validation_0-logloss:0.24473
[298]	validation_0-logloss:0.24456
[299]	validation_0-logloss:0.24446
[300]	validation_0-logloss:0.24456
[301]	validation_0-logloss:0.24456
[302]	validation_0-logloss:0.24463
[303]	validation_0-logloss:0.24487
[304]	validation_0-logloss:0.24507
[305]	validation_0-logloss:0.24505
[306]	validation_0-logloss:0.24520
[307]	validation_0-logloss:0.24524
[308]	validation_0-logloss:0.24534
[309]	validation_0-logloss:0.24513
[310]	validation_0-logloss:0.24533
[311]	validation_0-logloss:0.24543
[312]	validation_0-logloss:0.24559
[313]	validation_0-logloss:0.24557
[314]	validation_0-logloss:0.24578
[315]	validation_0-logloss:0.24571
[316]	validation_0-logloss:0.24585
[317]	validation_0-logloss:0.24616
[318]	validation_0-logloss:0.24608
[319]	validation_0-logloss:0.24614
[320]	validation_0-logloss:0.24614
[321]	validation_0-logloss:0.24620
[322]	validation_0-logloss:0.24614
[323]	validation_0-logloss:0.24608
[324]	validation_0-logloss:0.24618
[325]	validation_0-logloss:0.24637
[326]	validation_0-logloss:0.24679
[327]	validation_0-logloss:0.24686
[328]	validation_0-logloss:0.24686
[329]	validation_0-logloss:0.24696
[330]	validation_0-logloss:0.24720
[331]	validation_0-logloss:0.24736
[332]	validation_0-logloss:0.24743
[333]	validation_0-logloss:0.24765
[334]	validation_0-logloss:0.24758
[335]	validation_0-logloss:0.24756
[336]	validation_0-logloss:0.24738
[337]	validation_0-logloss:0.24742
[338]	validation_0-logloss:0.24759
[339]	validation_0-logloss:0.24763
[340]	validation_0-logloss:0.24768
[341]	validation_0-logloss:0.24787
[342]	validation_0-logloss:0.24801
[343]	validation_0-logloss:0.24806
[344]	validation_0-logloss:0.24827
[345]	validation_0-logloss:0.24849
[346]	validation_0-logloss:0.24856
[347]	validation_0-logloss:0.24861
[348]	validation_0-logloss:0.24875
[349]	validation_0-logloss:0.24891
[350]	validation_0-logloss:0.24870
[351]	validation_0-logloss:0.24894
[352]	validation_0-logloss:0.24895
[353]	validation_0-logloss:0.24903
[354]	validation_0-logloss:0.24917
[355]	validation_0-logloss:0.24930
[356]	validation_0-logloss:0.24938
[357]	validation_0-logloss:0.24934
[358]	validation_0-logloss:0.24969
[359]	validation_0-logloss:0.24969
[360]	validation_0-logloss:0.24995
[361]	validation_0-logloss:0.25008
[362]	validation_0-logloss:0.25027
[363]	validation_0-logloss:0.25037
[364]	validation_0-logloss:0.25030
[365]	validation_0-logloss:0.25026
[366]	validation_0-logloss:0.25052
[367]	validation_0-logloss:0.25067
[368]	validation_0-logloss:0.25051
[369]	validation_0-logloss:0.25061
[370]	validation_0-logloss:0.25077
[371]	validation_0-logloss:0.25076
[372]	validation_0-logloss:0.25085
[373]	validation_0-logloss:0.25099
[374]	validation_0-logloss:0.25102
[375]	validation_0-logloss:0.25102
[376]	validation_0-logloss:0.25112
[377]	validation_0-logloss:0.25128
[378]	validation_0-logloss:0.25140
[379]	validation_0-logloss:0.25139
[380]	validation_0-logloss:0.25146
[381]	validation_0-logloss:0.25167
[382]	validation_0-logloss:0.25182
[383]	validation_0-logloss:0.25194
[384]	validation_0-logloss:0.25217
[385]	validation_0-logloss:0.25209
[386]	validation_0-logloss:0.25215
[387]	validation_0-logloss:0.25208
[388]	validation_0-logloss:0.25213
[389]	validation_0-logloss:0.25238
[390]	validation_0-logloss:0.25232
[391]	validation_0-logloss:0.25235
[392]	validation_0-logloss:0.25245
[393]	validation_0-logloss:0.25233
[394]	validation_0-logloss:0.25236
[395]	validation_0-logloss:0.25240
[396]	validation_0-logloss:0.25261
[397]	validation_0-logloss:0.25265
[398]	validation_0-logloss:0.25284
[399]	validation_0-logloss:0.25300

XGBoost Training Time: 2.68 seconds
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;XGBoost Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>XGBoost Accuracy: 0.9111617312072893
              precision    recall  f1-score   support

           0       0.94      0.96      0.95       756
           1       0.72      0.60      0.65       122

    accuracy                           0.91       878
   macro avg       0.83      0.78      0.80       878
weighted avg       0.91      0.91      0.91       878

[[727  29]
 [ 49  73]]
</pre></div>
</div>
</div>
</div>
<p>CNN 1D (Deep Learning)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">MaxPooling1D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.callbacks</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callback</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># Gunakan data sebelum PCA</span>
<span class="n">X_train_cnn</span> <span class="o">=</span> <span class="n">X_train_scaled</span>
<span class="n">X_test_cnn</span>  <span class="o">=</span> <span class="n">X_test_scaled</span>

<span class="c1"># Reshape: (samples, timesteps, channels)</span>
<span class="n">X_train_cnn</span> <span class="o">=</span> <span class="n">X_train_cnn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_train_cnn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_train_cnn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_test_cnn</span>  <span class="o">=</span> <span class="n">X_test_cnn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test_cnn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_test_cnn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Conv1D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">MaxPooling1D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>

    <span class="n">Conv1D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">MaxPooling1D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>

    <span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train_cnn</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TimeHistory</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Progress: </span><span class="si">{</span><span class="n">progress</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">% | Elapsed: </span><span class="si">{</span><span class="n">elapsed</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">total</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Total CNN Training Time: </span><span class="si">{</span><span class="n">total</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>

<span class="n">time_callback</span> <span class="o">=</span> <span class="n">TimeHistory</span><span class="p">()</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train_cnn</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">time_callback</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">cnn_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_cnn</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">7s</span> 42ms/step - accuracy: 0.8611 - loss: 0.3892 - val_accuracy: 0.8805 - val_loss: 0.2907
Epoch 2/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.8924 - loss: 0.2993 - val_accuracy: 0.8861 - val_loss: 0.2909
Epoch 3/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.8969 - loss: 0.2710 - val_accuracy: 0.8918 - val_loss: 0.2846
Epoch 4/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9032 - loss: 0.2409 - val_accuracy: 0.8861 - val_loss: 0.2853
Epoch 5/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9016 - loss: 0.2409 - val_accuracy: 0.8786 - val_loss: 0.2964
Epoch 6/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9063 - loss: 0.2236 - val_accuracy: 0.8843 - val_loss: 0.2785
Epoch 7/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9132 - loss: 0.2097 - val_accuracy: 0.8748 - val_loss: 0.2933
Epoch 8/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9073 - loss: 0.2180 - val_accuracy: 0.8786 - val_loss: 0.2831
Epoch 9/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9107 - loss: 0.1919 - val_accuracy: 0.8861 - val_loss: 0.2741
Epoch 10/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9214 - loss: 0.1959 - val_accuracy: 0.8899 - val_loss: 0.3107
Epoch 11/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9145 - loss: 0.1869 - val_accuracy: 0.8805 - val_loss: 0.2951
Epoch 12/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 5ms/step - accuracy: 0.9287 - loss: 0.1750 - val_accuracy: 0.8805 - val_loss: 0.3280
Epoch 13/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 7ms/step - accuracy: 0.9450 - loss: 0.1525 - val_accuracy: 0.8861 - val_loss: 0.2883
Epoch 14/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9259 - loss: 0.1779 - val_accuracy: 0.8672 - val_loss: 0.2995
Epoch 15/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 5ms/step - accuracy: 0.9381 - loss: 0.1528 - val_accuracy: 0.8880 - val_loss: 0.2998
Epoch 16/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 7ms/step - accuracy: 0.9172 - loss: 0.1819 - val_accuracy: 0.8843 - val_loss: 0.3091
Epoch 17/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - accuracy: 0.9382 - loss: 0.1459 - val_accuracy: 0.8805 - val_loss: 0.3263
Epoch 18/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9298 - loss: 0.1639 - val_accuracy: 0.8748 - val_loss: 0.3047
Epoch 19/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9331 - loss: 0.1483 - val_accuracy: 0.8899 - val_loss: 0.3210
Epoch 20/20
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9427 - loss: 0.1359 - val_accuracy: 0.8843 - val_loss: 0.3726
Epoch 1/20
<span class=" -Color -Color-Bold">57/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9515 - loss: 0.1265Progress: 5.0% | Elapsed: 0.3s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 5ms/step - accuracy: 0.9517 - loss: 0.1260 - val_accuracy: 0.8748 - val_loss: 0.3436
Epoch 2/20
<span class=" -Color -Color-Bold">56/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9578 - loss: 0.1132Progress: 10.0% | Elapsed: 0.6s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9564 - loss: 0.1155 - val_accuracy: 0.8729 - val_loss: 0.3628
Epoch 3/20
<span class=" -Color -Color-Bold">57/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9460 - loss: 0.1274Progress: 15.0% | Elapsed: 0.9s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9463 - loss: 0.1270 - val_accuracy: 0.8861 - val_loss: 0.4152
Epoch 4/20
<span class=" -Color -Color-Bold">56/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9523 - loss: 0.1199Progress: 20.0% | Elapsed: 1.2s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9529 - loss: 0.1192 - val_accuracy: 0.8748 - val_loss: 0.3673
Epoch 5/20
<span class=" -Color -Color-Bold">52/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9561 - loss: 0.1062Progress: 25.0% | Elapsed: 1.5s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9555 - loss: 0.1083 - val_accuracy: 0.8653 - val_loss: 0.3728
Epoch 6/20
<span class=" -Color -Color-Bold">55/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9577 - loss: 0.1139Progress: 30.0% | Elapsed: 1.8s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9582 - loss: 0.1134 - val_accuracy: 0.8786 - val_loss: 0.3556
Epoch 7/20
<span class=" -Color -Color-Bold">55/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9640 - loss: 0.0916Progress: 35.0% | Elapsed: 2.1s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9632 - loss: 0.0931 - val_accuracy: 0.8729 - val_loss: 0.3669
Epoch 8/20
<span class=" -Color -Color-Bold">57/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9566 - loss: 0.1018Progress: 40.0% | Elapsed: 2.4s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9574 - loss: 0.1035 - val_accuracy: 0.8710 - val_loss: 0.4278
Epoch 9/20
<span class=" -Color -Color-Bold">56/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9590 - loss: 0.1067Progress: 45.0% | Elapsed: 2.7s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9592 - loss: 0.1075 - val_accuracy: 0.8748 - val_loss: 0.3947
Epoch 10/20
<span class=" -Color -Color-Bold">56/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9684 - loss: 0.0880Progress: 50.0% | Elapsed: 3.0s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9681 - loss: 0.0885 - val_accuracy: 0.8729 - val_loss: 0.4268
Epoch 11/20
<span class=" -Color -Color-Bold">57/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9678 - loss: 0.0894Progress: 55.0% | Elapsed: 3.3s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9677 - loss: 0.0891 - val_accuracy: 0.8691 - val_loss: 0.4344
Epoch 12/20
<span class=" -Color -Color-Bold">52/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9697 - loss: 0.0878Progress: 60.0% | Elapsed: 3.6s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9698 - loss: 0.0873 - val_accuracy: 0.8786 - val_loss: 0.4976
Epoch 13/20
<span class=" -Color -Color-Bold">56/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9633 - loss: 0.1024Progress: 65.0% | Elapsed: 3.9s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9641 - loss: 0.1009 - val_accuracy: 0.8634 - val_loss: 0.4648
Epoch 14/20
<span class=" -Color -Color-Bold">56/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9747 - loss: 0.0888Progress: 70.0% | Elapsed: 4.2s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9750 - loss: 0.0882 - val_accuracy: 0.8729 - val_loss: 0.4819
Epoch 15/20
<span class=" -Color -Color-Bold">55/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9823 - loss: 0.0699Progress: 75.0% | Elapsed: 4.4s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9811 - loss: 0.0715 - val_accuracy: 0.8786 - val_loss: 0.4657
Epoch 16/20
<span class=" -Color -Color-Bold">56/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9811 - loss: 0.0654Progress: 80.0% | Elapsed: 4.7s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9805 - loss: 0.0666 - val_accuracy: 0.8691 - val_loss: 0.5031
Epoch 17/20
<span class=" -Color -Color-Bold">55/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9760 - loss: 0.0797Progress: 85.0% | Elapsed: 5.0s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9764 - loss: 0.0777 - val_accuracy: 0.8767 - val_loss: 0.5153
Epoch 18/20
<span class=" -Color -Color-Bold">55/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9764 - loss: 0.0704Progress: 90.0% | Elapsed: 5.3s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9761 - loss: 0.0714 - val_accuracy: 0.8729 - val_loss: 0.5261
Epoch 19/20
<span class=" -Color -Color-Bold">51/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9758 - loss: 0.0741Progress: 95.0% | Elapsed: 5.6s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9757 - loss: 0.0744 - val_accuracy: 0.8729 - val_loss: 0.5392
Epoch 20/20
<span class=" -Color -Color-Bold">56/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.9733 - loss: 0.0675Progress: 100.0% | Elapsed: 5.9s
<span class=" -Color -Color-Bold">66/66</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9740 - loss: 0.0670 - val_accuracy: 0.8767 - val_loss: 0.5490

Total CNN Training Time: 5.94 seconds
<span class=" -Color -Color-Bold">28/28</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 17ms/step
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CNN-1D Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">cnn_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">cnn_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">cnn_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CNN-1D Accuracy: 0.9020501138952164
              precision    recall  f1-score   support

           0       0.94      0.95      0.94       756
           1       0.66      0.62      0.64       122

    accuracy                           0.90       878
   macro avg       0.80      0.79      0.79       878
weighted avg       0.90      0.90      0.90       878

[[716  40]
 [ 46  76]]
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="evaluation">
<h1>Evaluation<a class="headerlink" href="#evaluation" title="Link to this heading">#</a></h1>
<p>Evaluasi dilakukan menggunakan:</p>
<ul class="simple">
<li><p>Accuracy</p></li>
<li><p>Precision, Recall, F1-score (fokus kelas Electric Device)</p></li>
<li><p>Confusion Matrix</p></li>
<li><p>Perbandingan multi-model</p></li>
<li><p>Visualisasi PCA 2D</p></li>
</ul>
<section id="perbandingan-semua-model">
<h2>Perbandingan semua model<a class="headerlink" href="#perbandingan-semua-model" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">accuracy_results</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred</span><span class="p">),</span>
    <span class="s2">&quot;SVM&quot;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm_pred</span><span class="p">),</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred</span><span class="p">),</span>
    <span class="s2">&quot;CNN 1D&quot;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">cnn_pred</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">accuracy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span>
    <span class="n">accuracy_results</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s2">&quot;index&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">accuracy_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-152e4b6f-9231-4cde-96bd-694f886ffe66" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Random Forest</th>
      <td>0.911162</td>
    </tr>
    <tr>
      <th>XGBoost</th>
      <td>0.911162</td>
    </tr>
    <tr>
      <th>CNN 1D</th>
      <td>0.902050</td>
    </tr>
    <tr>
      <th>SVM</th>
      <td>0.866743</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-152e4b6f-9231-4cde-96bd-694f886ffe66')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-152e4b6f-9231-4cde-96bd-694f886ffe66 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-152e4b6f-9231-4cde-96bd-694f886ffe66');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-d7ba570b-3524-42ce-b7a5-122889ef7b52">
      <button class="colab-df-quickchart" onclick="quickchart('df-d7ba570b-3524-42ce-b7a5-122889ef7b52')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-d7ba570b-3524-42ce-b7a5-122889ef7b52 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

  <div id="id_2efed53a-7d78-4cae-a52f-79012b503c3c">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('accuracy_df')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_2efed53a-7d78-4cae-a52f-79012b503c3c button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('accuracy_df');
      }
      })();
    </script>
  </div>

    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">accuracy_df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">accuracy_df</span><span class="p">[</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Perbandingan Akurasi Model&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e525416925cbb9d4abb74ae8c7037b7b609624bf90edf4ad0230dc5353a0e268.png" src="_images/e525416925cbb9d4abb74ae8c7037b7b609624bf90edf4ad0230dc5353a0e268.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
        <span class="n">cm</span><span class="p">,</span>
        <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span>
        <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span>
        <span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;No Device&quot;</span><span class="p">,</span> <span class="s2">&quot;Electric Device&quot;</span><span class="p">],</span>
        <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;No Device&quot;</span><span class="p">,</span> <span class="s2">&quot;Electric Device&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Actual&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred</span><span class="p">,</span> <span class="s2">&quot;Random Forest Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm_pred</span><span class="p">,</span> <span class="s2">&quot;SVM Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred</span><span class="p">,</span> <span class="s2">&quot;XGBoost Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">cnn_pred</span><span class="p">,</span> <span class="s2">&quot;CNN 1D Confusion Matrix&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5a60a0619d14ff98883807b51638cd08468f7c7112a3469cb5993f914220ec56.png" src="_images/5a60a0619d14ff98883807b51638cd08468f7c7112a3469cb5993f914220ec56.png" />
<img alt="_images/bb51f387381c2d1979b1f49e1331886e32916aa728de6fcc570eec4298fcdae1.png" src="_images/bb51f387381c2d1979b1f49e1331886e32916aa728de6fcc570eec4298fcdae1.png" />
<img alt="_images/9b5cc7e8794ff0b523ae97578077c50d9bee8298931e1714b4d06b1f71df4319.png" src="_images/9b5cc7e8794ff0b523ae97578077c50d9bee8298931e1714b4d06b1f71df4319.png" />
<img alt="_images/bb424326d5e1dbcd72153815ae212a37adf85ebd817a89d2a036e337b489b710.png" src="_images/bb424326d5e1dbcd72153815ae212a37adf85ebd817a89d2a036e337b489b710.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">output_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span>
        <span class="s2">&quot;Precision (Device)&quot;</span><span class="p">:</span> <span class="n">report</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">][</span><span class="s2">&quot;precision&quot;</span><span class="p">],</span>
        <span class="s2">&quot;Recall (Device)&quot;</span><span class="p">:</span> <span class="n">report</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">][</span><span class="s2">&quot;recall&quot;</span><span class="p">],</span>
        <span class="s2">&quot;F1-Score (Device)&quot;</span><span class="p">:</span> <span class="n">report</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">][</span><span class="s2">&quot;f1-score&quot;</span><span class="p">]</span>
    <span class="p">}</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="n">get_metrics</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred</span><span class="p">),</span>
    <span class="s2">&quot;SVM&quot;</span><span class="p">:</span> <span class="n">get_metrics</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm_pred</span><span class="p">),</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">get_metrics</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred</span><span class="p">),</span>
    <span class="s2">&quot;CNN 1D&quot;</span><span class="p">:</span> <span class="n">get_metrics</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">cnn_pred</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
    <span class="n">by</span><span class="o">=</span><span class="s2">&quot;F1-Score (Device)&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">metrics_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-2db07d5b-e5c4-4de1-a888-21e8966f668b" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Accuracy</th>
      <th>Precision (Device)</th>
      <th>Recall (Device)</th>
      <th>F1-Score (Device)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>XGBoost</th>
      <td>0.911162</td>
      <td>0.715686</td>
      <td>0.598361</td>
      <td>0.651786</td>
    </tr>
    <tr>
      <th>CNN 1D</th>
      <td>0.902050</td>
      <td>0.655172</td>
      <td>0.622951</td>
      <td>0.638655</td>
    </tr>
    <tr>
      <th>Random Forest</th>
      <td>0.911162</td>
      <td>0.782051</td>
      <td>0.500000</td>
      <td>0.610000</td>
    </tr>
    <tr>
      <th>SVM</th>
      <td>0.866743</td>
      <td>0.515152</td>
      <td>0.696721</td>
      <td>0.592334</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-2db07d5b-e5c4-4de1-a888-21e8966f668b')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-2db07d5b-e5c4-4de1-a888-21e8966f668b button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-2db07d5b-e5c4-4de1-a888-21e8966f668b');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-b08e53d5-9097-4333-a8ce-9f811504f876">
      <button class="colab-df-quickchart" onclick="quickchart('df-b08e53d5-9097-4333-a8ce-9f811504f876')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-b08e53d5-9097-4333-a8ce-9f811504f876 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

  <div id="id_2f70535a-85e0-49e1-b0f3-bf179f2423d1">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('metrics_df')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_2f70535a-85e0-49e1-b0f3-bf179f2423d1 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('metrics_df');
      }
      })();
    </script>
  </div>

    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_model</span> <span class="o">=</span> <span class="n">metrics_df</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">best_metrics</span> <span class="o">=</span> <span class="n">metrics_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔎 MODEL TERBAIK BERDASARKAN F1-SCORE KELAS DEVICE&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model :&quot;</span><span class="p">,</span> <span class="n">best_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔎 MODEL TERBAIK BERDASARKAN F1-SCORE KELAS DEVICE
Model : XGBoost
Accuracy              0.911162
Precision (Device)    0.715686
Recall (Device)       0.598361
F1-Score (Device)     0.651786
Name: XGBoost, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Berdasarkan evaluasi:</p>
<ul class="simple">
<li><p>XGBoost dan Random Forest memiliki akurasi tertinggi (~91%)</p></li>
<li><p>XGBoost unggul dalam:</p>
<ul>
<li><p>F1-score kelas device</p></li>
<li><p>Precision–Recall tradeoff</p></li>
<li><p>Stabilitas prediksi</p></li>
</ul>
</li>
</ul>
<p>Sehingga XGBoost dipilih sebagai model utama untuk deployment.</p>
</section>
<section id="insight-evaluasi">
<h2>Insight Evaluasi<a class="headerlink" href="#insight-evaluasi" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Model cenderung lebih akurat mengenali non-device</p></li>
<li><p>Tantangan utama adalah false negative (device tidak terdeteksi)</p></li>
<li><p>Threshold probabilitas diperlukan untuk kontrol risiko</p></li>
</ul>
</section>
<section id="menyimpan-model">
<h2>Menyimpan model<a class="headerlink" href="#menyimpan-model" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>

<span class="c1"># Simpan scaler dan PCA</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="s2">&quot;scaler.pkl&quot;</span><span class="p">)</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">pca</span><span class="p">,</span> <span class="s2">&quot;pca.pkl&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scaler &amp; PCA berhasil disimpan&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Scaler &amp; PCA berhasil disimpan
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="s2">&quot;random_forest_model.pkl&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Random Forest berhasil disimpan&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest berhasil disimpan
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="s2">&quot;svm_model.pkl&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;SVM berhasil disimpan&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVM berhasil disimpan
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">xgb</span><span class="p">,</span> <span class="s2">&quot;xgboost_model.pkl&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;XGBoost berhasil disimpan&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>XGBoost berhasil disimpan
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;cnn_1d_model.keras&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CNN 1D berhasil disimpan (.keras)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CNN 1D berhasil disimpan (.keras)
</pre></div>
</div>
</div>
</div>
</section>
<section id="menyimpan-data-untuk-test-setelah-deployment">
<h2>Menyimpan data untuk test setelah deployment<a class="headerlink" href="#menyimpan-data-untuk-test-setelah-deployment" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Simpan 10 contoh deployment CSV</span>
<span class="n">deploy_samples</span> <span class="o">=</span> <span class="n">X_deploy</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">deploy_samples</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;deploy_input_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">.csv&quot;</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deploy_labels</span> <span class="o">=</span> <span class="n">y_deploy</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
<span class="n">deploy_labels</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;deploy_labels_groundtruth.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="deployment">
<h1>Deployment<a class="headerlink" href="#deployment" title="Link to this heading">#</a></h1>
<section id="implementasi-aplikasi">
<h2>Implementasi Aplikasi<a class="headerlink" href="#implementasi-aplikasi" title="Link to this heading">#</a></h2>
<p>Model XGBoost dideploy menggunakan Streamlit dengan fitur:</p>
<ul class="simple">
<li><p>Input:</p>
<ul>
<li><p>CSV histogram</p></li>
<li><p>Gambar X-ray</p></li>
<li><p>Input manual histogram</p></li>
</ul>
</li>
<li><p>Pipeline otomatis:
Input → Histogram → Scaling → PCA → XGBoost → Probabilitas</p></li>
<li><p>Confidence threshold</p></li>
<li><p>Alert level (LOW / MEDIUM / HIGH)</p></li>
</ul>
<section id="app-py">
<h3><a class="reference external" href="http://app.py">app.py</a><a class="headerlink" href="#app-py" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">streamlit</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">st</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">cv2</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">shap</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># =========================================================</span>
<span class="c1"># CONFIG</span>
<span class="c1"># =========================================================</span>
<span class="n">st</span><span class="o">.</span><span class="n">set_page_config</span><span class="p">(</span>
    <span class="n">page_title</span><span class="o">=</span><span class="s2">&quot;Electric Device Detection (X-ray)&quot;</span><span class="p">,</span>
    <span class="n">page_icon</span><span class="o">=</span><span class="s2">&quot;⚡&quot;</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="s2">&quot;centered&quot;</span>
<span class="p">)</span>

<span class="c1"># =========================================================</span>
<span class="c1"># LOAD MODEL &amp; PREPROCESSING</span>
<span class="c1"># =========================================================</span>
<span class="nd">@st</span><span class="o">.</span><span class="n">cache_resource</span><span class="p">(</span><span class="n">show_spinner</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_models</span><span class="p">():</span>
    <span class="n">xgb</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;xgboost_model.pkl&quot;</span><span class="p">)</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;scaler.pkl&quot;</span><span class="p">)</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;pca.pkl&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xgb</span><span class="p">,</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">pca</span>

<span class="n">xgb</span><span class="p">,</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">load_models</span><span class="p">()</span>

<span class="c1"># =========================================================</span>
<span class="c1"># LOAD SHAP EXPLAINER</span>
<span class="c1"># =========================================================</span>
<span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">xgb</span><span class="p">)</span>

<span class="c1"># =========================================================</span>
<span class="c1"># UTILITY FUNCTIONS</span>
<span class="c1"># =========================================================</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_likely_xray</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">std_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">std_g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">std_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">2</span><span class="p">])</span>

        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">std_r</span> <span class="o">-</span> <span class="n">std_g</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">15</span> <span class="ow">or</span> <span class="nb">abs</span><span class="p">(</span><span class="n">std_r</span> <span class="o">-</span> <span class="n">std_b</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">15</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_RGB2GRAY</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">80</span>


<span class="k">def</span><span class="w"> </span><span class="nf">image_to_histogram</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_RGB2GRAY</span><span class="p">)</span>

    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>

    <span class="n">hist</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">calcHist</span><span class="p">([</span><span class="n">img</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="p">[</span><span class="mi">256</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">hist</span> <span class="o">/</span> <span class="n">hist</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">if</span> <span class="n">hist</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">hist</span>


<span class="k">def</span><span class="w"> </span><span class="nf">preprocess_histogram</span><span class="p">(</span><span class="n">hist</span><span class="p">):</span>
    <span class="n">hist</span> <span class="o">=</span> <span class="n">hist</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hist_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">hist</span><span class="p">)</span>
    <span class="n">hist_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">hist_scaled</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">hist_pca</span>


<span class="k">def</span><span class="w"> </span><span class="nf">predict_histogram</span><span class="p">(</span><span class="n">hist</span><span class="p">):</span>
    <span class="n">hist_pca</span> <span class="o">=</span> <span class="n">preprocess_histogram</span><span class="p">(</span><span class="n">hist</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">hist_pca</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">hist_pca</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">pred</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">hist_pca</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_alert_level</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">prob</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;LOW&quot;</span><span class="p">,</span> <span class="s2">&quot;🟢&quot;</span><span class="p">,</span> <span class="s2">&quot;Risiko rendah&quot;</span>
    <span class="k">elif</span> <span class="n">prob</span> <span class="o">&lt;</span> <span class="mf">0.85</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;MEDIUM&quot;</span><span class="p">,</span> <span class="s2">&quot;🟡&quot;</span><span class="p">,</span> <span class="s2">&quot;Perlu pemeriksaan tambahan&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;HIGH&quot;</span><span class="p">,</span> <span class="s2">&quot;🔴&quot;</span><span class="p">,</span> <span class="s2">&quot;PERINGATAN: Risiko tinggi&quot;</span>


<span class="c1"># =========================================================</span>
<span class="c1"># UI</span>
<span class="c1"># =========================================================</span>
<span class="n">st</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;⚡ Electric Device Detection System&quot;</span><span class="p">)</span>

<span class="n">st</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sistem ini mendeteksi **perangkat listrik** dari:</span>
<span class="sd">    - 📄 **CSV histogram**</span>
<span class="sd">    - 🩻 **Gambar X-ray**</span>
<span class="sd">    - ⌨️ **Input manual histogram**</span>

<span class="sd">    Pipeline:</span>
<span class="sd">    **Histogram → StandardScaler → PCA → XGBoost**</span>
<span class="sd">    &quot;&quot;&quot;</span>
<span class="p">)</span>

<span class="n">st</span><span class="o">.</span><span class="n">markdown</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>

<span class="c1"># =========================================================</span>
<span class="c1"># CONFIDENCE THRESHOLD</span>
<span class="c1"># =========================================================</span>
<span class="n">st</span><span class="o">.</span><span class="n">subheader</span><span class="p">(</span><span class="s2">&quot;⚙️ Confidence Threshold&quot;</span><span class="p">)</span>

<span class="n">threshold</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">slider</span><span class="p">(</span>
    <span class="s2">&quot;Threshold probabilitas deteksi&quot;</span><span class="p">,</span>
    <span class="n">min_value</span><span class="o">=</span><span class="mf">0.50</span><span class="p">,</span>
    <span class="n">max_value</span><span class="o">=</span><span class="mf">0.90</span><span class="p">,</span>
    <span class="n">value</span><span class="o">=</span><span class="mf">0.70</span><span class="p">,</span>
    <span class="n">step</span><span class="o">=</span><span class="mf">0.05</span>
<span class="p">)</span>

<span class="n">st</span><span class="o">.</span><span class="n">markdown</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>

<span class="c1"># =========================================================</span>
<span class="c1"># INPUT METHOD</span>
<span class="c1"># =========================================================</span>
<span class="n">input_method</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">radio</span><span class="p">(</span>
    <span class="s2">&quot;Pilih metode input:&quot;</span><span class="p">,</span>
    <span class="p">[</span>
        <span class="s2">&quot;📄 Upload CSV Histogram&quot;</span><span class="p">,</span>
        <span class="s2">&quot;🩻 Upload Gambar X-ray&quot;</span><span class="p">,</span>
        <span class="s2">&quot;⌨️ Input Manual Histogram&quot;</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">histogram</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1"># =========================================================</span>
<span class="c1"># CSV INPUT</span>
<span class="c1"># =========================================================</span>
<span class="k">if</span> <span class="n">input_method</span> <span class="o">==</span> <span class="s2">&quot;📄 Upload CSV Histogram&quot;</span><span class="p">:</span>
    <span class="n">uploaded_csv</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">file_uploader</span><span class="p">(</span><span class="s2">&quot;Upload CSV (256 nilai)&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;csv&quot;</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">uploaded_csv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">uploaded_csv</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">256</span><span class="p">:</span>
            <span class="n">st</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;CSV harus berisi 256 nilai&quot;</span><span class="p">)</span>
            <span class="n">st</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

        <span class="n">histogram</span> <span class="o">=</span> <span class="n">data</span> <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">st</span><span class="o">.</span><span class="n">success</span><span class="p">(</span><span class="s2">&quot;Histogram CSV valid&quot;</span><span class="p">)</span>

<span class="c1"># =========================================================</span>
<span class="c1"># IMAGE INPUT</span>
<span class="c1"># =========================================================</span>
<span class="k">elif</span> <span class="n">input_method</span> <span class="o">==</span> <span class="s2">&quot;🩻 Upload Gambar X-ray&quot;</span><span class="p">:</span>
    <span class="n">uploaded_image</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">file_uploader</span><span class="p">(</span><span class="s2">&quot;Upload gambar X-ray&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;png&quot;</span><span class="p">,</span> <span class="s2">&quot;jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;jpeg&quot;</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">uploaded_image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">uploaded_image</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
        <span class="n">st</span><span class="o">.</span><span class="n">image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">caption</span><span class="o">=</span><span class="s2">&quot;X-ray Input&quot;</span><span class="p">,</span> <span class="n">use_column_width</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_likely_xray</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
            <span class="n">st</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;⚠️ Gambar kemungkinan bukan X-ray&quot;</span><span class="p">)</span>

        <span class="n">histogram</span> <span class="o">=</span> <span class="n">image_to_histogram</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># =========================================================</span>
<span class="c1"># MANUAL INPUT</span>
<span class="c1"># =========================================================</span>
<span class="k">elif</span> <span class="n">input_method</span> <span class="o">==</span> <span class="s2">&quot;⌨️ Input Manual Histogram&quot;</span><span class="p">:</span>
    <span class="n">manual_text</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">text_area</span><span class="p">(</span>
        <span class="s2">&quot;Masukkan 256 nilai histogram (dipisahkan koma / spasi)&quot;</span><span class="p">,</span>
        <span class="n">height</span><span class="o">=</span><span class="mi">200</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">manual_text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">manual_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()])</span>
            <span class="k">if</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">256</span><span class="p">:</span>
                <span class="n">st</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Jumlah nilai harus 256&quot;</span><span class="p">)</span>
                <span class="n">st</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

            <span class="n">histogram</span> <span class="o">=</span> <span class="n">values</span> <span class="o">/</span> <span class="n">values</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">st</span><span class="o">.</span><span class="n">success</span><span class="p">(</span><span class="s2">&quot;Histogram manual valid&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="n">st</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Input harus berupa angka&quot;</span><span class="p">)</span>

<span class="c1"># =========================================================</span>
<span class="c1"># PREDICTION + SHAP</span>
<span class="c1"># =========================================================</span>
<span class="k">if</span> <span class="n">histogram</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">st</span><span class="o">.</span><span class="n">button</span><span class="p">(</span><span class="s2">&quot;🔍 Jalankan Prediksi&quot;</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">st</span><span class="o">.</span><span class="n">spinner</span><span class="p">(</span><span class="s2">&quot;Memproses prediksi...&quot;</span><span class="p">):</span>
            <span class="n">pred</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">hist_pca</span> <span class="o">=</span> <span class="n">predict_histogram</span><span class="p">(</span><span class="n">histogram</span><span class="p">)</span>
            <span class="n">alert</span><span class="p">,</span> <span class="n">icon</span><span class="p">,</span> <span class="n">desc</span> <span class="o">=</span> <span class="n">get_alert_level</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>

        <span class="n">st</span><span class="o">.</span><span class="n">markdown</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
        <span class="n">st</span><span class="o">.</span><span class="n">subheader</span><span class="p">(</span><span class="s2">&quot;📊 Hasil Prediksi&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">prob</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">st</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">icon</span><span class="si">}</span><span class="s2"> PERANGKAT LISTRIK TERDETEKSI&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">st</span><span class="o">.</span><span class="n">success</span><span class="p">(</span><span class="s2">&quot;✅ TIDAK TERDETEKSI PERANGKAT LISTRIK&quot;</span><span class="p">)</span>

        <span class="n">st</span><span class="o">.</span><span class="n">metric</span><span class="p">(</span><span class="s2">&quot;Probabilitas Electric Device&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prob</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
        <span class="n">st</span><span class="o">.</span><span class="n">metric</span><span class="p">(</span><span class="s2">&quot;Alert Level&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">icon</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">alert</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">st</span><span class="o">.</span><span class="n">caption</span><span class="p">(</span><span class="n">desc</span><span class="p">)</span>

        <span class="n">st</span><span class="o">.</span><span class="n">subheader</span><span class="p">(</span><span class="s2">&quot;📈 Histogram (Normalized)&quot;</span><span class="p">)</span>
        <span class="n">st</span><span class="o">.</span><span class="n">line_chart</span><span class="p">(</span><span class="n">histogram</span><span class="p">)</span>

        <span class="c1"># =================================================</span>
        <span class="c1"># SHAP EXPLANATION</span>
        <span class="c1"># =================================================</span>
        <span class="n">st</span><span class="o">.</span><span class="n">markdown</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
        <span class="n">st</span><span class="o">.</span><span class="n">subheader</span><span class="p">(</span><span class="s2">&quot;🧠 Penjelasan Model (SHAP)&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">st</span><span class="o">.</span><span class="n">expander</span><span class="p">(</span><span class="s2">&quot;Lihat penjelasan keputusan model&quot;</span><span class="p">):</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">hist_pca</span><span class="p">)</span>

            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">shap</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
                <span class="n">shap</span><span class="o">.</span><span class="n">Explanation</span><span class="p">(</span>
                    <span class="n">values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="n">base_values</span><span class="o">=</span><span class="n">explainer</span><span class="o">.</span><span class="n">expected_value</span><span class="p">,</span>
                    <span class="n">data</span><span class="o">=</span><span class="n">hist_pca</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="n">feature_names</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;PC</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hist_pca</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
                <span class="p">),</span>
                <span class="n">max_display</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">show</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">st</span><span class="o">.</span><span class="n">pyplot</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

<span class="c1"># =========================================================</span>
<span class="c1"># FOOTER</span>
<span class="c1"># =========================================================</span>
<span class="n">st</span><span class="o">.</span><span class="n">markdown</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
<span class="n">st</span><span class="o">.</span><span class="n">caption</span><span class="p">(</span><span class="s2">&quot;Model: XGBoost | Explainable AI (SHAP) | End-to-End System&quot;</span><span class="p">)</span>
<span class="n">st</span><span class="o">.</span><span class="n">caption</span><span class="p">(</span><span class="s2">&quot;Developed by NRSF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="requirements-txt">
<h3>requirements.txt<a class="headerlink" href="#requirements-txt" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">streamlit</span>
<span class="n">numpy</span>
<span class="n">scikit</span><span class="o">-</span><span class="n">learn</span>
<span class="n">joblib</span>
<span class="n">opencv</span><span class="o">-</span><span class="n">python</span><span class="o">-</span><span class="n">headless</span>
<span class="n">Pillow</span>
<span class="n">xgboost</span>
<span class="n">shap</span>
<span class="n">matplotlib</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="explainability-shap">
<h2>Explainability (SHAP)<a class="headerlink" href="#explainability-shap" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Untuk meningkatkan kepercayaan pengguna:</p></li>
<li><p>Digunakan SHAP TreeExplainer</p></li>
<li><p>Menampilkan fitur PCA yang paling berpengaruh</p></li>
<li><p>Mendukung interpretasi keputusan model</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="conclusion-future-work">
<h1>Conclusion &amp; Future Work<a class="headerlink" href="#conclusion-future-work" title="Link to this heading">#</a></h1>
<section id="kesimpulan">
<h2>Kesimpulan<a class="headerlink" href="#kesimpulan" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Sistem berhasil mendeteksi perangkat listrik dari citra X-ray</p></li>
<li><p>Pendekatan histogram + ML terbukti efektif</p></li>
<li><p>XGBoost memberikan performa terbaik secara keseluruhan</p></li>
</ul>
</section>
<section id="pengembangan-lanjutan">
<h2>Pengembangan Lanjutan<a class="headerlink" href="#pengembangan-lanjutan" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Integrasi CNN 3D langsung dari voxel</p></li>
<li><p>Penambahan ensemble model</p></li>
<li><p>Kalibrasi threshold berbasis risiko bandara</p></li>
<li><p>Dataset real-world tambahan</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="time-series_autocorr-based.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Analisis Data Time Series</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Projek UAS</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#business-understanding">Business Understanding</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#latar-belakang">Latar Belakang</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tujuan-bisnis">Tujuan Bisnis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definisi-masalah">Definisi Masalah</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-understanding">Data Understanding</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-dataset">Deskripsi Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-library">Load Library</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-data-konversi-label">LOAD DATA &amp; KONVERSI LABEL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cek-struktur-data">CEK STRUKTUR DATA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribusi-kelas">DISTRIBUSI KELAS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#missing-value-check">MISSING VALUE CHECK</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistik-deskriptif">STATISTIK DESKRIPTIF</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribusi-nilai-fitur-global">DISTRIBUSI NILAI FITUR (GLOBAL)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi-1-sampel">VISUALISASI 1 SAMPEL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-rata-rata-per-kelas">PERBANDINGAN RATA-RATA PER KELAS</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#heatmap-korelasi">HEATMAP KORELASI</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#outlier-detection-z-score">OUTLIER DETECTION (Z-SCORE)</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#variansi-fitur">VARIANSI FITUR</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#temuan-awal-dari-eda">Temuan Awal dari EDA</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation">Data Preparation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing">PREPROCESSING</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#penggabungan-dataset">Penggabungan Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tahapan-preprocessing">Tahapan Preprocessing</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#validasi-penanganan-missing-value">VALIDASI &amp; PENANGANAN MISSING VALUE</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-outlier-dengan-clipping">HANDLING OUTLIER DENGAN CLIPPING</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-scaling">FEATURE SCALING</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-reduksi-dimensi">PCA – REDUKSI DIMENSI</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-output-untuk-modeling">FINAL OUTPUT UNTUK MODELING</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling">Modeling</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">Evaluation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-semua-model">Perbandingan semua model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insight-evaluasi">Insight Evaluasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menyimpan-model">Menyimpan model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menyimpan-data-untuk-test-setelah-deployment">Menyimpan data untuk test setelah deployment</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#deployment">Deployment</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-aplikasi">Implementasi Aplikasi</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#app-py">app.py</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#requirements-txt">requirements.txt</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explainability-shap">Explainability (SHAP)</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-future-work">Conclusion &amp; Future Work</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">Kesimpulan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pengembangan-lanjutan">Pengembangan Lanjutan</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 23-100 Naufal Rabbani Sab'ul FItri
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>